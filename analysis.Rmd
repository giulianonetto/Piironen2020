---
title: Reproducing Piironen2020
author: Giuliano
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r setup, include = FALSE}
# Set knitr options ------------------------------------------------------------
knitr::opts_chunk$set(
  echo = TRUE
)


# Load packages ----------------------------------------------------------------
library(tidyverse)
library(brms)
library(projpred)


# Source auxiliary R files -----------------------------------------------------
source("R/functions.R")
```

# Generate data

The function `generate_data_01` returns a `data.frame` with y and x variables according to the data generating process from equation (1) in [Piironen (2020)](https://doi.org/10.1214/20-EJS1711). The first `p_rel` x variables should be pairwise correlated with $\rho = 0.3$ (for this example) and have marginal variances equal to $1$. The remaining x variables should be independent, standard normal random variables.

Generate the data.

```{r}
fake_data <- generate_data_01(N = 1e4, p = 10, rho = 0.3, p_rel = 5)
head(fake_data) %>% 
  kableExtra::kable() %>% 
  kableExtra::kable_styling()
```

Check if correlations match. 

```{r part-1}

fake_data %>% 
  select(-y) %>% 
  cor() %>% data.frame() %>% rownames_to_column('name0') %>% 
  pivot_longer(col = contains('X')) %>% 
  mutate(name0 = factor(name0, levels = paste0("X", 1:10)),
         name = factor(name, levels = paste0("X", 1:10))) %>% 
  ggplot(aes(name0, name, fill = value)) +
  geom_tile() +
  geom_text(aes(label = round(value, 2)), color = "white") +
  labs(x = NULL, y = NULL, fill = "Correlation")
```

Check if marginal variances match.

```{r}
hist(matrixStats::colVars(as.matrix(fake_data[,-1])),
     main = "X variances")
```

Good enough! Let's generate a realization following the specifications in the paper.

```{r}
df <- generate_data_01(
  N = 50,
  p = 500,
  rho = 0.3,
  p_rel = 150
)
```


# Reference model

In the experiment from Fig 7, the authors performed Supervised Principal Component analysis and used the first 3 PCs in their regression. I will do a simplified version of their workflow using simple linear regression on the computed PCs and using $\gamma = 0.1$ as the (absolute) correlation threshold in the screening step before PCA.

```{r}
features_to_keep <- df %>% 
  select(-y) %>% 
  map_lgl(~ abs(cor(.x, df$y)) > 0.1)
pca <- prcomp(df[, features_to_keep])
new_X <- pca$x[, 1:3] 
```

Out of 150 relevant features, with this screening we kept

```{r}
sum(paste0("X", 1:150) %in% names(features_to_keep[features_to_keep]))
```

for further processing with PCA. A total of

```{r}
sum(features_to_keep)
```

features passed the screening (out of 500).

Using `y` and `new_X`, we fit the reference model.

```{r}
df_reduced <- data.frame(
  y = df$y,
  new_X
)
ref_model <- lm(
  y ~ PC1 + PC2 + PC3,
  data = df_reduced
)
```

# Benefit of a reference model (LASSO only)

The authors make the claim that a reference model may be useful in selecting variables because it generates an estimate of $f$, $f_*$, which hopefully increases the discrimination between 'bad' and 'good' features. Let's see if that holds with LASSO alone.

Fit the models

```{r}
library(glmnet)

X <- as.matrix(df[, -1])
y <- df[, 1]
y_ref <- predict(ref_model)
fit_no_ref <- cv.glmnet(X, y)
fit_ref <- cv.glmnet(X, y_ref)
```

Generate large test set for external validation.

```{r}
test_data <- generate_data_01(
  N = 1e5,
  p = 500,
  rho = 0.3,
  p_rel = 150
)
```

Compute performance for the model without reference model.

```{r}
preds_no_ref <- predict(fit_no_ref, 
                        newx = as.matrix(test_data[, -1]),
                        s = "lambda.1se")
rmse_no_ref <- rmse(preds_no_ref[, 1], test_data$y) %>% round(2)
str_glue("RMSE without reference: {rmse_no_ref}")
```

With the reference model.

```{r}
preds_ref <- predict(fit_ref, 
                     newx = as.matrix(test_data[, -1]),
                     s = "lambda.1se")
rmse_ref <- rmse(preds_ref[, 1], test_data$y) %>% round(2)
str_glue("RMSE with reference: {rmse_ref}")
```

The model with reference seems better. Let's look at the regularization paths.

```{r}
par(mfrow = c(1,2))
plot(fit_no_ref, ylim = c(0,2.5), main = "LASSO")
plot(fit_ref, ylim = c(0,2.5), main = "LASSO + reference model")
```


This thing seems to work! Let's encapsulate everything we've done inside a function and then repeat this simulation multiple times.

```{r}
simulate_reference_model_effect <- function(
  N = 50,
  p = 500,
  rho = 0.3,
  p_rel = 150,
  gamma = 0.1,
  PCs_to_keep = 3,
  sim = NULL,
  test_data = NULL,
  .verbose = FALSE,
  data_gen_method = NULL,
  ...
) {
  
  if (!is.null(sim) & isTRUE(.verbose)) {
    print(str_glue("Simulation: {sim}"))
  }
  
  # generate observations
  if (is.null(data_gen_method)) {
    df <- generate_data_01(N = N, p = p, rho = rho, p_rel = p_rel)
  } else {
    df <- data_gen_method(N = N, p = p, rho = rho, p_rel = p_rel, ... = ...)
  }
  
  
  # screen features + SPCA
  features_to_keep <- df %>% 
    select(-y) %>% 
    map_lgl(
      ~ ifelse(all(.x==1), TRUE, abs(cor(.x, df$y)) > gamma)
    )
  
  df_subset <- df[, features_to_keep]
  pca <- prcomp(df_subset)
  new_X <- pca$x[, 1:PCs_to_keep]
  
  # fit reference model
  df_reduced <- data.frame(y = df$y, new_X)
  ref_model <- lm(y ~ ., data = df_reduced)
  
  # fit LASSO models
  X <- as.matrix(df[, -1])
  y <- df[, 1]
  y_ref <- predict(ref_model)
  fit_no_ref <- glmnet::cv.glmnet(X, y)
  fit_ref <- glmnet::cv.glmnet(X, y_ref)
  
  # fit Bayes model for projpred
  #fit_proj <- fit_projpred(df = df)
  fit_proj <- fit_homemade_proj(df = df, 
                                fit_l1 = fit_no_ref,
                                y_ref = y_ref)
  
  # generate test data
  if (is.null(test_data)) {
    if (is.null(data_gen_method)) {
      test_data <- generate_data_01(
        N = 5e4, p = p, rho = rho, p_rel = p_rel
      )
    } else {
      test_data <- data_gen_method(
        N = 5e4, p = p,  rho = rho, p_rel = p_rel, ...
      )
    }
    
  }
  # test predictions without reference
  preds_no_ref <- predict(fit_no_ref, 
                          newx = as.matrix(test_data[, -1]),
                          s = "lambda.1se")
  rmse_no_ref <- rmse(preds_no_ref[, 1], test_data$y)
  
  # test predictions with reference
  preds_ref <- predict(fit_ref, 
                       newx = as.matrix(test_data[, -1]),
                       s = "lambda.1se")
  rmse_ref <- rmse(preds_ref[, 1], test_data$y)
  
  # test predictions of reference model
  new_X_test <- predict(pca, newdata = test_data[, features_to_keep])
  preds_ref_model <- predict(ref_model, newdata =  data.frame(new_X_test))
  rmse_ref_model <- rmse(preds_ref_model, test_data$y)
  
  # test predictions projpred
  preds_proj <- predict(fit_proj, newdata = test_data[, -1])
  rmse_proj <- rmse(preds_proj, test_data$y)
  
  # get sizes of each model (number of variables selected)
  b_no_ref <- coef(fit_no_ref, s = 'lambda.1se') %>% as.matrix()
  b_ref <- coef(fit_ref, s = 'lambda.1se') %>% as.matrix()
  b_proj <- coef(fit_proj)
  size_no_ref <- sum(abs(b_no_ref) > 0 )
  size_ref <- sum(abs(b_ref) > 0 )
  size_proj <- sum(abs(b_proj) > 0 )
  
  # get proportion of (in) correctly selected variables
  kept_no_ref <- rownames(b_no_ref)[abs(b_no_ref) > 0][-1]  # exclude intercept
  kept_ref <- rownames(b_ref)[abs(b_ref) > 0][-1]
  kept_proj <- names(b_proj)[-1]
  rel_features <- paste0("X", 1:p_rel)
  tp_no_ref <- sum(rel_features %in% kept_no_ref)
  tp_ref <- sum(rel_features %in% kept_ref)
  tp_proj <- sum(rel_features %in% kept_proj)
  fp_no_ref <- sum(!(kept_no_ref %in% rel_features))
  fp_ref <- sum(!(kept_ref %in% rel_features))
  fp_proj <- sum(!(kept_proj %in% rel_features))
  
  return(data.frame(
    rmse_no_ref, rmse_ref, rmse_ref_model, rmse_proj,
    size_no_ref, size_ref, size_proj,
    tp_no_ref, tp_ref, tp_proj,
    fp_no_ref, fp_ref, fp_proj
  ))
}
```

Let's simulate 100 realizations of the experiment.

```{r, max.height='100px'}
set.seed(123)
test_ix <- sample(1:nrow(test_data), 2e4)
simulation <- map(
  1:500,
  ~ simulate_reference_model_effect(
    sim = .x, 
    test_data = test_data[test_ix,]
  )
) %>% 
  bind_rows(.id = "sim")
```

Plot the results.

```{r}
library(patchwork)
theme_set(theme_bw())

mutate_name <- function(x, pfx) {
  x %>% 
    mutate(
      name = case_when(
        name == str_glue("{pfx}_ref") ~ "enet + ref",
        name == str_glue("{pfx}_no_ref") ~ "enet",
        name == str_glue("{pfx}_proj") ~ "projection",
        T ~ "Ref (SPCA)"
      )
    )
}

p1 <- simulation %>% 
  pivot_longer(cols = contains('rmse')) %>% 
  mutate_name("rmse") %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "RMSE")
p2 <- simulation %>% 
  pivot_longer(cols = contains('size')) %>% 
  mutate_name("size") %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "# kept variables")
p3 <- simulation %>% 
  pivot_longer(cols = contains('tp')) %>% 
  mutate_name("tp") %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "# TP")
p4 <- simulation %>% 
  pivot_longer(cols = contains('fp')) %>% 
  mutate_name("fp") %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "# FP") 

(p1 + p2) / (p3 + p4)
```

Showing the observed values for each simulation.

```{r}
f <- function(p) {
  p + 
    geom_line(
      aes(group = sim),
      alpha = .3,
      position = ggbeeswarm::position_quasirandom(width = .2)
    ) +
    geom_point(
      alpha = .3,
      position = ggbeeswarm::position_quasirandom(width = .2)
    ) 
}

(f(p1) + f(p2)) / (f(p3) + f(p4))
```

I wonder if this is an artifact of our reference model. Let's use a data generation process that is slightly different and see if the effect remains.

$$
\begin{align*}
&y_i \sim \mathcal{N}(\mathbb{X}\beta, 1) \\
&\beta = \left(\beta_0, \beta_1, \cdots, \beta_{p_{rel}}, 0, 0, \cdots, 0 \right) \\
&x_{\cdot, 1} = 1 \\ 
&x_{i,j} \sim \mathcal{N}(0, 1) \ \ \ \ \  i \in \{1, \cdots, N\},\ j \in \{2, \cdots, p\}
\end{align*}
$$
Basically, we will choose a coefficient vector with $p_{rel}$ non-zero terms (one of which is the intercept). The predictors will be mutually independent. For this example, we will sample the non-zero coefficients from an uniform on $[1, 5]$. The intercept will be $10$.

```{r, max.height='100px'}
set.seed(123)
.beta <- c(1, runif(p_rel - 1, 50, 100), rep(0, p - p_rel))
test_data <- generate_data_02(N=1e4)
set.seed(123)
simulation <- map(
  1:100,
  ~ simulate_reference_model_effect(
    sim = .x, 
    data_gen_method = generate_data_02,
    gamma = 0.1,
    test_data = test_data,
    beta = .beta
  )
) %>% 
  bind_rows(.id = "sim")
```

```{r}

p1 <- simulation %>% 
  pivot_longer(cols = contains('rmse')) %>% 
  mutate(
    name = case_when(
      name == "rmse_ref" ~ "LASSO + ref",
      name == "rmse_no_ref" ~"LASSO",
      T ~ "Ref (SPCA)"
    )
  ) %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "RMSE")
p2 <- simulation %>% 
  pivot_longer(cols = contains('size')) %>% 
  mutate(
    name = case_when(
      name == "size_ref" ~ "LASSO + ref",
      name == "size_no_ref" ~"LASSO",
      T ~ "Ref (SPCA)"
    )
  ) %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "# kept variables")
p3 <- simulation %>% 
  pivot_longer(cols = contains('tp')) %>% 
  mutate(
    name = case_when(
      name == "tp_ref" ~ "LASSO + ref",
      name == "tp_no_ref" ~"LASSO",
      T ~ "Ref (SPCA)"
    )
  ) %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "# TP")
p4 <- simulation %>% 
  pivot_longer(cols = contains('fp')) %>% 
  mutate(
    name = case_when(
      name == "fp_ref" ~ "LASSO + ref",
      name == "fp_no_ref" ~"LASSO",
      T ~ "Ref (SPCA)"
    )
  ) %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "# FP") 

(p1 + p2) / (p3 + p4)
```

Showing the observed values for each simulation.

```{r}
f <- function(p) {
  p + 
    geom_line(
      aes(group = sim),
      alpha = .3,
      position = ggbeeswarm::position_quasirandom(width = .2)
    ) +
    geom_point(
      alpha = .3,
      position = ggbeeswarm::position_quasirandom(width = .2)
    ) 
}

(f(p1) + f(p2)) / (f(p3) + f(p4))
```

I wonder if this is an artifact of our reference model. Let's use a data generation process that is slightly different and see if the effect remains.

$$
\begin{align*}
&y_i \sim \mathcal{N}(\mathbb{X}\beta, 1) \\
&\beta = \left(\beta_0, \beta_1, \cdots, \beta_{p_{rel}}, 0, 0, \cdots, 0 \right) \\
&x_{\cdot, 1} = 1 \\ 
&x_{i,j} \sim \mathcal{N}(0, 1) \ \ \ \ \  i \in \{1, \cdots, N\},\ j \in \{2, \cdots, p\}
\end{align*}
$$
Basically, we will choose a coefficient vector with $p_{rel}$ non-zero terms (one of which is the intercept). The predictors will be mutually independent. For this example, we will sample the non-zero coefficients from an uniform on $[1, 5]$. The intercept will be $10$.

```{r, max.height='100px'}
set.seed(123)
.beta <- c(1, runif(p_rel - 1, 50, 100), rep(0, p - p_rel))
test_data <- generate_data_02(N=1e4)
set.seed(123)
simulation <- map(
  1:100,
  ~ simulate_reference_model_effect(
    sim = .x, 
    data_gen_method = generate_data_02,
    gamma = 0.1,
    test_data = test_data,
    beta = .beta
  )
) %>% 
  bind_rows(.id = "sim")
```

```{r}

p1 <- simulation %>% 
  pivot_longer(cols = contains('rmse')) %>% 
  mutate(
    name = case_when(
      name == "rmse_ref" ~ "LASSO + ref",
      name == "rmse_no_ref" ~"LASSO",
      T ~ "Ref (SPCA)"
    )
  ) %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "RMSE")
p2 <- simulation %>% 
  pivot_longer(cols = contains('size')) %>% 
  mutate(
    name = case_when(
      name == "size_ref" ~ "LASSO + ref",
      name == "size_no_ref" ~"LASSO",
      T ~ "Ref (SPCA)"
    )
  ) %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "# kept variables")
p3 <- simulation %>% 
  pivot_longer(cols = contains('tp')) %>% 
  mutate(
    name = case_when(
      name == "tp_ref" ~ "LASSO + ref",
      name == "tp_no_ref" ~"LASSO",
      T ~ "Ref (SPCA)"
    )
  ) %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "# TP")
p4 <- simulation %>% 
  pivot_longer(cols = contains('fp')) %>% 
  mutate(
    name = case_when(
      name == "fp_ref" ~ "LASSO + ref",
      name == "fp_no_ref" ~"LASSO",
      T ~ "Ref (SPCA)"
    )
  ) %>% 
  ggplot(aes(name, value)) +
  geom_boxplot(alpha = 0, width = .5, lwd = 1) +
  labs(x = NULL, y = "# FP") 

(p1 + p2) / (p3 + p4)
```


